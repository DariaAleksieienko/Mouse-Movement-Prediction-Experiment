{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Path to training and validation datasets\n",
    "\n",
    "train_data_path = 'C:\\Users\\aleks\\Documents\\KSA\\MaturaPaper\\Data\\DataOfMouse\\mouse.csv'\n",
    "val_data_path = 'C:\\Users\\aleks\\Documents\\KSA\\MaturaPaper\\Data\\DataOfMouse\\validation.csv'\n",
    "test_data_path = 'C:\\Users\\aleks\\Documents\\KSA\\MaturaPaper\\Data\\DataOfMouse\\test.csv'  \n",
    "\n",
    "# Path to new dataset\n",
    "\n",
    "# read data and convert into numpy arrays\n",
    "train_data = pd.read_csv(train_data_path, sep=',', header=None)\n",
    "val_data = pd.read_csv(val_data_path, sep=',', header=None)\n",
    "test_data = pd.read_csv(test_data_path, sep=',', header=None)\n",
    "\n",
    "train_x = train_data.iloc[:,0:50].to_numpy()\n",
    "train_y = train_data.iloc[:,50].to_numpy()\n",
    "\n",
    "print(train_x)\n",
    "print(train_y)\n",
    "\n",
    "val_x = val_data.iloc[:,0:50].to_numpy()\n",
    "val_y = val_data.iloc[:,50].to_numpy()\n",
    "\n",
    "test_x = test_data.iloc[:,0:50].to_numpy()\n",
    "test_y = test_data.iloc[:,50].to_numpy()\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(50, activation='sigmoid', input_dim = 50),\n",
    "    Dense(5, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "print(\"compile model complete\")\n",
    "\n",
    "# Train the model with validation\n",
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=300)\n",
    "print(\"fit data complete\")\n",
    "\n",
    "# Make predictions on the new dataset\n",
    "predictions = model.predict(test_x)\n",
    "rounded = np.concatenate( tf.round(predictions).numpy() )\n",
    "\n",
    "print(test_y)\n",
    "print(rounded)\n",
    "# print(predictions)\n",
    "\n",
    "comparison = test_y == rounded\n",
    "\n",
    "# Count the number of same and different items\n",
    "same_count = np.sum(comparison)\n",
    "different_count = len(test_y) - same_count\n",
    "\n",
    "print(\"Same count:\", same_count)\n",
    "print(\"Different count:\", different_count)\n",
    "\n",
    "print(\"Hit rate: \", same_count / (same_count + different_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
